{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea8024eb"
   },
   "source": [
    "# Setting up the tools (this takes a moment)\n",
    "\n",
    "Before we start, we need to install some essential tools to process audio and video. Think of these as the software needed on your computer to run the next steps. This will take a few moments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0055f2f8"
   },
   "source": [
    "## Upload your audio or video file\n",
    "\n",
    "Now, it's time to upload the file you want to transcribe. This could be an audio file (like an MP3 or WAV) or a video file (like an MP4 or MOV). Click the \"Choose Files\" button that appears below to select your file from your computer.\n",
    "\n",
    "Once uploaded, the notebook will remember where your file is saved so we can use it in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "!apt -y install ffmpeg\n",
    "\n",
    "# Python deps (local only, no paid API)\n",
    "!pip install -q faster-whisper aksharamukha open-tamil pydub\n",
    "\n",
    "# If you get GPU, this will be 🔥 fast. Otherwise it still runs on CPU.\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxrYayZYPDOW",
    "outputId": "4b90dc64-cb43-4b24-f17f-18b14fa252b4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.6/2.6 MB\u001B[0m \u001B[31m45.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m65.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m289.9/289.9 kB\u001B[0m \u001B[31m26.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m39.9/39.9 MB\u001B[0m \u001B[31m19.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m38.8/38.8 MB\u001B[0m \u001B[31m19.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m16.5/16.5 MB\u001B[0m \u001B[31m109.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m97.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m526.8/526.8 kB\u001B[0m \u001B[31m39.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.0/46.0 kB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.8/86.8 kB\u001B[0m \u001B[31m8.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Building wheel for open-tamil (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for jaconv (setup.py) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T03:31:55.458301Z",
     "start_time": "2025-09-21T03:31:55.161343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1) Verify GPU present\n",
    "!nvidia-smi"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 21 09:01:55 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.88                 Driver Version: 576.88         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   55C    P0             18W /   82W |       7MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            6348    C+G   ...rm 2024.3.2\\bin\\pycharm64.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "\n",
    "# Change this to your audio/video file (wav/mp3/m4a/mp4/mov etc. all fine)\n",
    "# AUDIO_PATH = \"/content/Solar_1.mp3\"\n",
    "\n",
    "# Upload a file\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the path of the uploaded file\n",
    "if uploaded:\n",
    "  AUDIO_PATH = list(uploaded.keys())[0]\n",
    "  print(f\"Uploaded file: {AUDIO_PATH}\")\n",
    "else:\n",
    "  AUDIO_PATH = None\n",
    "  print(\"No file uploaded.\")\n",
    "\n",
    "\n",
    "assert Path(AUDIO_PATH).exists(), f\"File not found: {AUDIO_PATH}\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "C1M6Sz-aPHur",
    "outputId": "116c0983-f877-45a3-a4b3-21e2879542ee",
    "ExecuteTime": {
     "end_time": "2025-09-21T03:31:57.713034Z",
     "start_time": "2025-09-21T03:31:56.684252Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpathlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Path\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m files\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Change this to your audio/video file (wav/mp3/m4a/mp4/mov etc. all fine)\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# AUDIO_PATH = \"/content/Solar_1.mp3\"\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Upload a file\u001B[39;00m\n\u001B[0;32m      8\u001B[0m uploaded \u001B[38;5;241m=\u001B[39m files\u001B[38;5;241m.\u001B[39mupload()\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transcribe (offline) with faster-whisper"
   ],
   "metadata": {
    "id": "3YCtoLwTPsod"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# 2) Install with CUDA-enabled ctranslate2 (safe to re-run)\n",
    "!pip install -q --upgrade \"faster-whisper>=1.0.0\" \"ctranslate2>=4.4,<5\"\n",
    "\n",
    "# 3) Run Whisper on GPU in float16\n",
    "from faster_whisper import WhisperModel\n",
    "import math, os\n",
    "\n",
    "AUDIO_PATH = \"/content/Solar_1.mp3\"  # your file\n",
    "\n",
    "# Pick a size that fits VRAM:\n",
    "# \"small\" (~1.2GB), \"medium\" (~3GB), \"large-v3\" (~9GB)\n",
    "MODEL_SIZE = \"large-v3\"\n",
    "\n",
    "# Force GPU + FP16\n",
    "model = WhisperModel(\n",
    "    MODEL_SIZE,\n",
    "    device=\"cuda\",              # <-- THIS is the fix\n",
    "    compute_type=\"float16\",     # fast on T4/L4/A100\n",
    ")\n",
    "\n",
    "segments, info = model.transcribe(\n",
    "    AUDIO_PATH,\n",
    "    language=\"ta\",                         # force Tamil\n",
    "    vad_filter=True,                       # keeps segments clean\n",
    "    vad_parameters=dict(min_silence_duration_ms=300),\n",
    "    beam_size=1,                           # greedy = faster\n",
    "    temperature=0.0,                       # faster/consistent\n",
    "    condition_on_previous_text=False,      # speed boost\n",
    "    word_timestamps=False,\n",
    ")\n",
    "\n",
    "print(f\"Language: {info.language} | Duration: {info.duration:.1f}s\")\n",
    "seg_list = list(segments)\n",
    "print(\"Segments:\", len(seg_list))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1H4P6uF1PooQ",
    "outputId": "736f8783-6710-4ba1-c73b-501e65957d25"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sat Sep 20 04:16:41 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   48C    P0             26W /   70W |    3206MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Language: ta | Duration: 75.6s\n",
      "Segments: 19\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Helpers: time formatting + SRT writer"
   ],
   "metadata": {
    "id": "SbSKml8kP5FF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def srt_timestamp(t):\n",
    "    # t in seconds → \"HH:MM:SS,mmm\"\n",
    "    hours = int(t // 3600)\n",
    "    minutes = int((t % 3600) // 60)\n",
    "    seconds = int(t % 60)\n",
    "    millis = int((t - math.floor(t)) * 1000)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d},{millis:03d}\"\n",
    "\n",
    "def write_srt(segments, texts, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, (seg, txt) in enumerate(zip(segments, texts), start=1):\n",
    "            f.write(str(i) + \"\\n\")\n",
    "            f.write(srt_timestamp(seg.start) + \" --> \" + srt_timestamp(seg.end) + \"\\n\")\n",
    "            f.write(txt.strip() + \"\\n\\n\")\n"
   ],
   "metadata": {
    "id": "sj_ZY3eHPuok"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tamil → Tanglish transliteration"
   ],
   "metadata": {
    "id": "T9A5mHYmP-wZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Option A: Aksharamukha (Tamil → Latin)\n",
    "from aksharamukha import transliterate as ak_trans\n",
    "\n",
    "def ta_to_tanglish_ak(text):\n",
    "    # \"ISO\" gives clean Latin; \"IAST\" is also possible.\n",
    "    # If you want looser \"WhatsApp-style\" spellings, see the open-tamil fallback below.\n",
    "    return ak_trans.process(\"Tamil\", \"ISO\", text)\n",
    "\n",
    "# Option B (fallback): open-tamil (Azhagi flavor)\n",
    "# NOTE: This creates ASCII-style phonetics many Tamil users type with.\n",
    "try:\n",
    "    from tamil.transliterate import azhagi\n",
    "    def ta_to_tanglish_azhagi(text):\n",
    "        # azhagi supports Unicode→ASCII style mapping\n",
    "        return azhagi.Unicode2ASCII(text)\n",
    "    HAVE_AZHAGI = True\n",
    "except Exception:\n",
    "    HAVE_AZHAGI = False\n",
    "\n",
    "def ta_to_tanglish(text):\n",
    "    try:\n",
    "        out = ta_to_tanglish_ak(text)\n",
    "        # Post-fix: lowercase for subtitle friendliness\n",
    "        return out.lower()\n",
    "    except Exception:\n",
    "        if HAVE_AZHAGI:\n",
    "            return ta_to_tanglish_azhagi(text).lower()\n",
    "        else:\n",
    "            # If everything fails, just return original\n",
    "            return text\n"
   ],
   "metadata": {
    "id": "I6iWCRP3QAcn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build the outputs (Tanglish SRT + Tamil SRT + TXT)"
   ],
   "metadata": {
    "id": "RnQPI7EgQGA4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tamil_lines = [s.text.strip() for s in seg_list]\n",
    "tanglish_lines = [ta_to_tanglish(s.text) for s in seg_list]\n",
    "\n",
    "# Files\n",
    "TGL_SRT = \"/content/output_tanglish.srt\"\n",
    "TA_SRT  = \"/content/output_tamil.srt\"\n",
    "TGL_TXT = \"/content/output_tanglish.txt\"\n",
    "\n",
    "# Write SRTs\n",
    "write_srt(seg_list, tanglish_lines, TGL_SRT)\n",
    "write_srt(seg_list, tamil_lines, TA_SRT)\n",
    "\n",
    "# Plain Tanglish transcript\n",
    "with open(TGL_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(tanglish_lines))\n",
    "\n",
    "TGL_SRT, TA_SRT, TGL_TXT\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4kvTAFKQGYL",
    "outputId": "4b2dd27b-5145-4e24-a3eb-b0b720f717a6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('/content/output_tanglish.srt',\n",
       " '/content/output_tamil.srt',\n",
       " '/content/output_tanglish.txt')"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "(Optional) Clean-up rules for more “WhatsApp-Tanglish"
   ],
   "metadata": {
    "id": "KZOd-AlbQVf5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def casualize_tanglish(line):\n",
    "    # vibe tweaks: aa → a, oo → u in some contexts, remove double spaces, etc.\n",
    "    line = re.sub(r\"\\bnaa\\b\", \"na\", line)   # naa → na\n",
    "    line = re.sub(r\"oo\", \"u\", line)         # food→fud style, careful but okay for captions\n",
    "    line = re.sub(r\"\\s{2,}\", \" \", line)\n",
    "    return line\n",
    "\n",
    "tanglish_lines_relaxed = [casualize_tanglish(l) for l in tanglish_lines]\n",
    "write_srt(seg_list, tanglish_lines_relaxed, \"/content/output_tanglish_relaxed.srt\")\n",
    "\"/content/output_tanglish_relaxed.srt\"\n"
   ],
   "metadata": {
    "id": "w9zLWUvKQVEF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "More refined\n"
   ],
   "metadata": {
    "id": "iu00ccqGYtuX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# --- Install once per runtime ---\n",
    "!apt -y install ffmpeg\n",
    "!pip install -q aksharamukha\n",
    "\n",
    "import re, math\n",
    "from pathlib import Path\n",
    "from aksharamukha import transliterate as ak_trans\n",
    "\n",
    "# ==== Paths ====\n",
    "IN_SRT_TA = Path(\"/content/output_tamil.srt\")           # your Tamil SRT\n",
    "OUT_SRT_TANGLISH = Path(\"/content/output_tanglish_v2.srt\")\n",
    "OUT_TXT_TANGLISH = Path(\"/content/output_tanglish_v2.txt\")\n",
    "OVERRIDES_PATH = Path(\"/content/tanglish_overrides.txt\")\n",
    "\n",
    "assert IN_SRT_TA.exists(), f\"Missing: {IN_SRT_TA}\"\n",
    "\n",
    "# ==== Style toggles ====\n",
    "PREFER_LA_FOR_ZH = True    # True: \"la\" (tamila) | False: \"zh\" (tamizh)\n",
    "\n",
    "# ISO (with diacritics) -> ASCII social mapping\n",
    "ISO_TO_ASCII = {\n",
    "    # long vowels\n",
    "    \"ā\": \"aa\", \"ī\": \"ii\", \"ū\": \"uu\",\n",
    "    \"ē\": \"e\",  \"ō\": \"o\",\n",
    "    # consonants w/ diacritics\n",
    "    \"ṭ\": \"t\", \"ḍ\": \"d\", \"ṇ\": \"n\", \"ṉ\": \"n\", \"ṅ\": \"ng\", \"ñ\": \"ny\",\n",
    "    \"ḷ\": \"l\", \"ḻ\": \"zh\", \"ṟ\": \"r\", \"ś\": \"sh\", \"ṣ\": \"sh\",\n",
    "    \"ṁ\": \"m\", \"ḥ\": \"h\",\n",
    "    # punctuation/oddities\n",
    "    \"’\": \"\", \"'\": \"\",\n",
    "}\n",
    "\n",
    "def iso_to_ascii_social(s: str) -> str:\n",
    "    # 1) diacritics -> ascii\n",
    "    s = \"\".join(ISO_TO_ASCII.get(ch, ch) for ch in s)\n",
    "    # 2) zh -> la if you prefer\n",
    "    if PREFER_LA_FOR_ZH:\n",
    "        s = re.sub(r\"zh\", \"la\", s)\n",
    "    # 3) subtle colloquial passes (conservative)\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"\\s{2,}\", \" \", s) # Fixed: Added s as the third argument\n",
    "    s = re.sub(r\"\\billai\\b\", \"illa\", s) # Fixed: Added s as the third argument\n",
    "    s = re.sub(r\"\\beppadi\\b\", \"epdi\", s)   # vibe-y short form # Fixed: Added s as the third argument\n",
    "    s = re.sub(r\"\\birukku\\b\", \"irukku\", s) # Fixed: Added s as the third argument\n",
    "    s = re.sub(r\"\\bvaa?ng[a|o]?\\b\", \"vaanga\", s)  # broad catch; tweak later # Fixed: Added s as the third argument\n",
    "    return s\n",
    "\n",
    "# Default overrides (Tamil->Tanglish) applied BEFORE transliteration\n",
    "DEFAULT_OVERRIDES = {\n",
    "    \"தமிழ்\": \"tamil\",\n",
    "    \"வணக்கம்\": \"vanakkam\",\n",
    "    \"பண்ணுங்க\": \"pannunga\",\n",
    "    \"எப்படி\": \"epdi\",\n",
    "    \"இல்லை\": \"illa\",\n",
    "    \"சரி\": \"seri\",\n",
    "    \"மன்னிக்கவும்\": \"mannikkavum\",\n",
    "    \"நன்றி\": \"nandri\",\n",
    "    \"உங்களுக்கு\": \"ungalukku\",\n",
    "    \"என்ன\": \"enna\",\n",
    "    \"வேண்டும்\": \"venum\",\n",
    "    \"இருக்கு\": \"irukku\"\n",
    "}\n",
    "\n",
    "# Create a template overrides file if it doesn’t exist\n",
    "if not OVERRIDES_PATH.exists():\n",
    "    OVERRIDES_PATH.write_text(\n",
    "        \"# Tamil\\tTanglish (your preferred spelling)\\n\"\n",
    "        \"# Example lines:\\n\"\n",
    "        \"அண்ணன்\\tannan\\n\"\n",
    "        \"எல்லாம்\\tyellam\\n\",\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "# Load user overrides (tab-separated)\n",
    "USER_OVERRIDES = {}\n",
    "for line in OVERRIDES_PATH.read_text(encoding=\"utf-8\").splitlines():\n",
    "    line = line.strip()\n",
    "    if not line or line.startswith(\"#\") or \"\\t\" not in line:\n",
    "        continue\n",
    "    ta, tg = line.split(\"\\t\", 1)\n",
    "    USER_OVERRIDES[ta.strip()] = tg.strip()\n",
    "\n",
    "TAMIL_RE = re.compile(r\"[\\u0B80-\\u0BFF]\")\n",
    "\n",
    "def apply_overrides_tamil_stage(tamil_text: str) -> str:\n",
    "    # replace longer strings first\n",
    "    pairs = sorted({**DEFAULT_OVERRIDES, **USER_OVERRIDES}.items(),\n",
    "                   key=lambda x: len(x[0]), reverse=True)\n",
    "    out = tamil_text\n",
    "    for ta, tg in pairs:\n",
    "        out = re.sub(re.escape(ta), tg, out)\n",
    "    return out\n",
    "\n",
    "def tamil_to_tanglish(line: str) -> str:\n",
    "    if not TAMIL_RE.search(line):\n",
    "        return line\n",
    "    pre = apply_overrides_tamil_stage(line)\n",
    "    # Tamil -> ISO Latin\n",
    "    iso = ak_trans.process(\"Tamil\", \"ISO\", pre)\n",
    "    # ISO -> ASCII Tanglish vibe\n",
    "    return iso_to_ascii_social(iso)\n",
    "\n",
    "def is_timestamp_line(line: str) -> bool:\n",
    "    return bool(re.match(r\"\\d{2}:\\d{2}:\\d{2},\\d{3}\\s-->\\s\\d{2}:\\d{2}:\\d{2},\\d{3}\", line.strip()))\n",
    "\n",
    "def convert_srt(in_path: Path, out_path: Path, out_txt: Path):\n",
    "    tanglish_lines = []\n",
    "    out_lines = []\n",
    "    for raw in in_path.read_text(encoding=\"utf-8\").splitlines():\n",
    "        if not raw.strip():\n",
    "            out_lines.append(raw)\n",
    "            continue\n",
    "        if raw.strip().isdigit() or is_timestamp_line(raw):\n",
    "            out_lines.append(raw)\n",
    "            continue\n",
    "        new = tamil_to_tanglish(raw)\n",
    "        out_lines.append(new)\n",
    "        if new.strip() and not new.strip().isdigit() and not is_timestamp_line(new):\n",
    "            tanglish_lines.append(new)\n",
    "\n",
    "    out_path.write_text(\"\\n\".join(out_lines), encoding=\"utf-8\")\n",
    "    out_txt.write_text(\"\\n\".join(tanglish_lines), encoding=\"utf-8\")\n",
    "\n",
    "convert_srt(IN_SRT_TA, OUT_SRT_TANGLISH, OUT_TXT_TANGLISH)\n",
    "\n",
    "print(\"Done ✅\")\n",
    "print(\"Tanglish SRT:\", OUT_SRT_TANGLISH)\n",
    "print(\"Tanglish TXT:\", OUT_TXT_TANGLISH)\n",
    "print(\"Overrides file:\", OVERRIDES_PATH)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oenz-GEKXISo",
    "outputId": "f9b3d20c-5e3e-4ad6-e62a-e0e60cd75aa1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
      "Done ✅\n",
      "Tanglish SRT: /content/output_tanglish_v2.srt\n",
      "Tanglish TXT: /content/output_tanglish_v2.txt\n",
      "Overrides file: /content/tanglish_overrides.txt\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
